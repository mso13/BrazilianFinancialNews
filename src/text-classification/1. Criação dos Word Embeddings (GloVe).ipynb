{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Criação GloVe Embeddings\n",
    "\n",
    "- Carregar os dados de cada site\n",
    "    - Suno\n",
    "    - Infomoney\n",
    "    - MoneyTimes\n",
    "- Realizar o preprocessamento\n",
    "- Concatenar em arquivo .txt\n",
    "- Realizar o procedimento descrito na documentação do GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../crawlers/suno/data/results-full-suno-2020.json', encoding='utf8') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "df_suno = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../crawlers/money-times/data/results-full-moneytimes-2020.json', encoding='utf8') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "df_moneytimes = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../crawlers/infomoney/data/results-full-infomoney-2020.json', encoding='utf8') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "df_infomoney = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(sentence):\n",
    "\n",
    "    \"Remoção de Emojis nas mensagens de texto.\"\n",
    "\n",
    "    # Padrões dos Emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                u\"\\U00002702-\\U000027B0\"\n",
    "                u\"\\U000024C2-\\U0001F251\"\n",
    "                u\"\\U0001f926-\\U0001f937\"\n",
    "                u'\\U00010000-\\U0010ffff'\n",
    "                u\"\\u200d\"\n",
    "                u\"\\u2640-\\u2642\"\n",
    "                u\"\\u2600-\\u2B55\"\n",
    "                u\"\\u23cf\"\n",
    "                u\"\\u23e9\"\n",
    "                u\"\\u231a\"\n",
    "                u\"\\u3030\"\n",
    "                u\"\\ufe0f\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    return emoji_pattern.sub(r'', sentence)\n",
    "\n",
    "def remove_valores(sentence):\n",
    "    new_sentece = ''\n",
    "    \n",
    "    for token in sentence.split():\n",
    "        if token.isdigit():\n",
    "            token = '<NUM>'\n",
    "        new_sentece += ' {}'.format(token)\n",
    "        \n",
    "    return new_sentece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Aplicar preprocessamento nos títulos e textos completos\n",
    "\n",
    "for df in [df_suno, df_infomoney, df_moneytimes]:\n",
    "\n",
    "    # Substituir símbolos importantes\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('-feira', ''))\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('+', 'mais '))\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('-', 'menos '))\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('%', ' por cento'))\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('R$', ''))\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('U$', ''))\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('US$', ''))\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('S&P 500', 'spx'))\n",
    "\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('-feira', ''))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('+', 'mais '))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('-', 'menos '))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('%', ' por cento'))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('R$', ''))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('U$', ''))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('US$', ''))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('S&P 500', 'spx'))\n",
    "\n",
    "    # Transformar em String e Letras Minúsculas nas Mensagens\n",
    "    df['title'] = df['title'].map(lambda s: str(s).lower())\n",
    "    df['full_text'] = df['full_text'].map(lambda s: str(s).lower())\n",
    "\n",
    "    # Remover Pontuações\n",
    "    df['title'] = df['title'].map(lambda s: s.translate(str.maketrans('', '', string.punctuation)))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "    # Remover Emojis     \n",
    "    df['title'] = df['title'].map(lambda s: remove_emojis(s))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: remove_emojis(s))\n",
    "\n",
    "    # Quebras de Linha desnecessárias\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('\\n', ' '))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('\\n', ' '))\n",
    "\n",
    "    # Remover aspas duplas\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('\\\"', ''))\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('“', ''))\n",
    "    df['title'] = df['title'].map(lambda s: s.replace('”', ''))\n",
    "\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('\\\"', ''))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('“', ''))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.replace('”', ''))\n",
    "\n",
    "    # Remover valores\n",
    "    df['title'] = df['title'].map(lambda s: remove_valores(s))\n",
    "    df['full_text'] = df['full_text'].map(lambda s: remove_valores(s))\n",
    "\n",
    "    # Espaços desnecessários\n",
    "    df['title'] = df['title'].map(lambda s: s.strip())\n",
    "    df['full_text'] = df['full_text'].map(lambda s: s.strip())\n",
    "    \n",
    "    # Salvar os textos completos em arquivo .txt\n",
    "    df['title'].to_csv('full_text.txt', index=False, mode='a')\n",
    "    df['full_text'].to_csv('full_text.txt', index=False, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizar procedimento da documentação do Glove..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.0",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
